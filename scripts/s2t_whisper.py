
import time
import os
import wave
import pyaudio

import streamlit as st

from pathlib import Path
from openai import OpenAI

from .modules.audio_parameter import (
    CHUNK              ,
    FORMAT             ,
    SAMPLE_RATE        ,
    CHANNELS           ,
    INPUT_DEVICE_INDEX ,
    CALL_BACK_FREQUENCY,
)

from .utils_streamlit import (
    change_mic_state_to_disabled, 
    change_recording_state_to_true
)

client = OpenAI(
    api_key=os.environ["OPENAI_API_KEY"]
)

# ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
OUTPUT_TXT_FILE = Path(__file__).parent.parent / "data" / "user_speech.txt"
AUDIO_FILE_PATH = Path(__file__).parent.parent / "sounds" / "output.wav"



def record_audio():
    
    with wave.open('sounds/output.wav', 'wb') as wf:
        
        p = pyaudio.PyAudio()
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(p.get_sample_size(FORMAT))
        wf.setframerate(SAMPLE_RATE)

        stream = p.open(format=FORMAT, channels=CHANNELS, rate=SAMPLE_RATE, input=True)

        print('Recording...')
        
        # éŒ²éŸ³åœæ­¢ãƒœã‚¿ãƒ³ã‚’é…ç½®ã—ã¦ãŠã
        with st.sidebar:
            st.button(
                label    = "Recording Stop ğŸ¤",
                key      = f"mic_stop",
                on_click = change_recording_state_to_true
            ) 
    
        while not st.session_state.is_stop_recording:
            
            # stream ã‹ã‚‰èª­ã¿è¾¼ã¿å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
            in_data = stream.read(CHUNK)
            wf.writeframes(in_data)
                
        print('Done')

        stream.close()
        p.terminate()


# éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã™ã‚‹
def speech_2_text():

    # éŒ²éŸ³åœæ­¢ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸéš›ã«ãƒªãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦éŒ²éŸ³ãŒäºŒé‡ã«ã•ã‚Œã¦ã—ã¾ã†å•é¡Œã‚’
    # å›é¿ã™ã‚‹ãŸã‚ã«ï¼ŒéŒ²éŸ³æ“ä½œã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ãƒ•ãƒ©ã‚°ã«ã‚ˆã‚Šå‡¦ç†ã‚’åˆ†å²
    if not st.session_state.is_skip_recording :
        record_audio()
    
    audio_file = open(AUDIO_FILE_PATH, "rb")
    transcript = client.audio.transcriptions.create(
        model           = "whisper-1", 
        file            = audio_file,
        language        = "en",
        response_format = "text"
    )
    
    # éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã—ãŸã®ã¡ï¼Œãƒœã‚¿ãƒ³ã‚’ able ã«
    change_mic_state_to_disabled(disabled=False)
    
    # éŒ²éŸ³é–¢é€£ã®ãƒ•ãƒ©ã‚°ã‚’åˆæœŸåŒ–
    st.session_state.is_stop_recording  = False
    st.session_state.is_skip_recording  = False
    st.session_state.is_still_recording = False
    
    return transcript


def main():
    speech_2_text()


if __name__ == '__main__':
    main()