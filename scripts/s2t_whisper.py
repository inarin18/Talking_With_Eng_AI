
import time
import os
import wave
import pyaudio

import streamlit as st

from pathlib import Path
from openai import OpenAI

from .modules.audio_parameter import (
    CHUNK              ,
    FORMAT             ,
    SAMPLE_RATE        ,
    CHANNELS           ,
    INPUT_DEVICE_INDEX ,
    CALL_BACK_FREQUENCY,
)

from .utils_streamlit import (
    change_mic_state_to_disabled, 
    change_recording_state_to_true
)

client = OpenAI(
    api_key=os.environ["OPENAI_API_KEY"]
)

# ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
OUTPUT_TXT_FILE = Path(__file__).parent.parent / "data" / "user_speech.txt"
AUDIO_FILE_PATH = Path(__file__).parent.parent / "sounds" / "output.wav"



def record_audio():
    
    with wave.open('sounds/output.wav', 'wb') as wf:
        
        p = pyaudio.PyAudio()
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(p.get_sample_size(FORMAT))
        wf.setframerate(SAMPLE_RATE)

        stream = p.open(format=FORMAT, channels=CHANNELS, rate=SAMPLE_RATE, input=True)

        print('Recording...')
        
        # éŒ²éŸ³åœæ­¢ãƒœã‚¿ãƒ³ã‚’é…ç½®ã—ã¦ãŠã
        with st.sidebar:
            stop_button_placeholder = st.empty()
        
        placeholder = st.empty()
    
        key_suffix  = 0
        while True:
            
            # stream ã‹ã‚‰èª­ã¿è¾¼ã¿å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
            in_data = stream.read(CHUNK)
            wf.writeframes(in_data)
        
            # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«éŒ²éŸ³åœæ­¢ãƒœã‚¿ãƒ³ã‚’é…ç½®
            with stop_button_placeholder.container():
                
                is_stop = st.button(
                    label    = "Recording Stop ğŸ¤",
                    key      = f"mic_stop_{key_suffix}",
                    on_click = change_recording_state_to_true
                ) 
            
            if st.session_state.is_stop_recording : break
            
            placeholder.write(f"Recording... {key_suffix}")
            
            # è¤‡è£½ç¦æ­¢ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹ã®ã‚’é˜²ããŸã‚ã« key_suffix ã®æ›´æ–°
            key_suffix += 1
            
            time.sleep(1)
                
        print('Done')
        
        stop_button_placeholder.empty()

        stream.close()
        p.terminate()


# éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã™ã‚‹
def speech_2_text():

    # éŒ²éŸ³åœæ­¢ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸéš›ã«ãƒªãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦éŒ²éŸ³ãŒäºŒé‡ã«ã•ã‚Œã¦ã—ã¾ã†å•é¡Œã‚’
    # å›é¿ã™ã‚‹ãŸã‚ã«ï¼ŒéŒ²éŸ³æ“ä½œã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ãƒ•ãƒ©ã‚°ã«ã‚ˆã‚Šå‡¦ç†ã‚’åˆ†å²
    if not st.session_state.is_skip_recording :
        record_audio()
    
    audio_file = open(AUDIO_FILE_PATH, "rb")
    transcript = client.audio.transcriptions.create(
        model           = "whisper-1", 
        file            = audio_file,
        language        = "en",
        response_format = "text"
    )
    
    # éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã—ãŸã®ã¡ï¼Œãƒœã‚¿ãƒ³ã‚’ able ã«
    change_mic_state_to_disabled(disabled=False)
    
    # éŒ²éŸ³é–¢é€£ã®ãƒ•ãƒ©ã‚°ã‚’åˆæœŸåŒ–
    st.session_state.is_stop_recording  = False
    st.session_state.is_skip_recording  = False
    st.session_state.is_still_recording = False
    
    return transcript


def main():
    speech_2_text()


if __name__ == '__main__':
    main()